# cogs/backup_manager.py
# -*- coding: utf-8 -*-

import logging
import discord
from discord import app_commands
from discord.ext import commands, tasks
import datetime
from typing import TYPE_CHECKING, Optional, Tuple
import os
import subprocess
import zipfile
import shutil
from pathlib import Path
import asyncio
import io
import traceback

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Google API
from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
from googleapiclient.errors import HttpError

if TYPE_CHECKING:
    from main import SecurityBot

logger = logging.getLogger(__name__)

def is_bot_owner_classic():
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö –∫–æ–º–∞–Ω–¥, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∞–≤—Ç–æ—Ä —Å–æ–æ–±—â–µ–Ω–∏—è
    –≤–ª–∞–¥–µ–ª—å—Ü–µ–º –±–æ—Ç–∞.
    """
    async def predicate(ctx: commands.Context) -> bool:
        owner_id = os.getenv("OWNER_DISCORD_ID")
        if not owner_id:
            return False
        try:
            return ctx.author.id == int(owner_id)
        except ValueError:
            return False
    return commands.check(predicate)


class BackupManagerCog(commands.Cog, name="–ú–µ–Ω–µ–¥–∂–µ—Ä –ë—ç–∫–∞–ø–æ–≤"):
    """
    –≠—Ç–æ—Ç –∫–æ–≥ –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏ —Ä—É—á–Ω–æ–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ
    –¥–∞–Ω–Ω—ã—Ö –∏ –∫–æ–¥–∞ –±–æ—Ç–∞ –≤ –æ–±–ª–∞—á–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ Google Drive.
    """
    def __init__(self, bot: "SecurityBot"):
        self.bot = bot
        self.t = self.bot.translator.get
        
        # --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ---
        self.CWD = Path.cwd()
        self.BOT_PATH = self.CWD
        self.LOCAL_BACKUP_PATH = self.CWD / "backups_system" / "local"
        self.CREDENTIALS_FILE = self.CWD / "credentials.json"
        self.TOKEN_FILE = self.CWD / "token.json"
        
        self.DB_USER = os.getenv("DB_USER")
        self.DB_PASS = os.getenv("DB_PASSWORD")
        self.DB_NAME = os.getenv("DB_NAME")
        self.MYSQLDUMP_PATH = Path("C:/Program Files/MySQL/MySQL Server 8.4/bin/mysqldump.exe")
        
        self.GDRIVE_FOLDER_NAME = "BotBackups"
        self.SCOPES = ["https://www.googleapis.com/auth/drive.file"]
        
        self.DATA_RETENTION_DAYS = 30
        self.CODE_RETENTION_DAYS = 90
        self.CODE_BACKUP_DAY = 6 # 0=–ü–Ω, 6=–í—Å
        
        self._is_task_running = False
        
        self.backup_task.start()

    def cog_unload(self):
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Ñ–æ–Ω–æ–≤—É—é –∑–∞–¥–∞—á—É –ø—Ä–∏ –≤—ã–≥—Ä—É–∑–∫–µ –∫–æ–≥–∞."""
        self.backup_task.cancel()
    
    # --- GOOGLE DRIVE HELPERS ---
    async def get_gdrive_service(self):
        """–ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç—Å—è —á–µ—Ä–µ–∑ OAuth 2.0 –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–∫—Ç —Å–µ—Ä–≤–∏—Å–∞ Google Drive."""
        creds = None
        if self.TOKEN_FILE.exists():
            creds = Credentials.from_authorized_user_file(str(self.TOKEN_FILE), self.SCOPES)
        
        if not creds or not creds.valid:
            if creds and creds.expired and creds.refresh_token:
                await self.bot.loop.run_in_executor(None, creds.refresh, Request())
            else:
                logger.error("–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç token.json. –¢—Ä–µ–±—É–µ—Ç—Å—è —Ä—É—á–Ω–∞—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è.")
                return None
            
            with open(self.TOKEN_FILE, "w") as token:
                token.write(creds.to_json())
        
        return build("drive", "v3", credentials=creds)

    async def find_or_create_folder(self, service, folder_name, parent_id=None):
        """–ù–∞—Ö–æ–¥–∏—Ç –ø–∞–ø–∫—É –ø–æ –∏–º–µ–Ω–∏ –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç –µ–µ, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."""
        query = f"name='{folder_name}' and mimeType='application/vnd.google-apps.folder' and trashed=false"
        if parent_id:
            query += f" and '{parent_id}' in parents"
        
        response = await self.bot.loop.run_in_executor(None, lambda:
            service.files().list(q=query, spaces="drive", fields="files(id, name)").execute()
        )
        files = response.get("files", [])
        
        if files:
            return files[0].get("id")
        else:
            logger.info(f"–ü–∞–ø–∫–∞ '{folder_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, —Å–æ–∑–¥–∞—é –Ω–æ–≤—É—é...")
            file_metadata = {'name': folder_name, 'mimeType': 'application/vnd.google-apps.folder'}
            if parent_id:
                file_metadata['parents'] = [parent_id]
            folder = await self.bot.loop.run_in_executor(None, lambda:
                service.files().create(body=file_metadata, fields="id").execute()
            )
            return folder.get("id")

    async def upload_file(self, service, file_path, folder_id):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –∑–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∞–π–ª –≤ —É–∫–∞–∑–∞–Ω–Ω—É—é –ø–∞–ø–∫—É –Ω–∞ Google Drive."""
        file_metadata = {'name': file_path.name, 'parents': [folder_id]}
        media = MediaFileUpload(str(file_path), mimetype='application/zip', resumable=True)
        try:
            await self.bot.loop.run_in_executor(None, lambda:
                service.files().create(body=file_metadata, media_body=media, fields="id").execute()
            )
            logger.info(f"–§–∞–π–ª '{file_path.name}' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –≤ –ø–∞–ø–∫—É ID: {folder_id}.")
            return True
        except HttpError as error:
            logger.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: {error}")
            return False

    async def cleanup_old_files(self, service, folder_id, days_to_keep):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —É–¥–∞–ª—è–µ—Ç —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ, –∫–æ—Ç–æ—Ä—ã–µ —Å—Ç–∞—Ä—à–µ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–Ω–µ–π."""
        if days_to_keep <= 0: return
        
        cutoff_date = (datetime.datetime.now(datetime.timezone.utc) - datetime.timedelta(days=days_to_keep)).isoformat()
        query = f"'{folder_id}' in parents and createdTime < '{cutoff_date}' and trashed=false"
        
        response = await self.bot.loop.run_in_executor(None, lambda:
            service.files().list(q=query, spaces="drive", fields="files(id, name)").execute()
        )
        files_to_delete = response.get("files", [])
        
        for file in files_to_delete:
            try:
                await self.bot.loop.run_in_executor(None, lambda:
                    service.files().delete(fileId=file.get("id")).execute()
                )
                logger.info(f"–£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π –æ–±–ª–∞—á–Ω—ã–π –±—ç–∫–∞–ø: {file.get('name')}")
            except HttpError as error:
                logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª '{file.get('name')}': {error}")

    # --- BACKUP LOGIC HELPERS ---
    async def run_subprocess(self, command, **kwargs):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –∑–∞–ø—É—Å–∫–∞–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ."""
        process = await asyncio.create_subprocess_exec(*command, **kwargs)
        await process.wait()
        return process

    async def backup_database(self, temp_dir):
        """–°–æ–∑–¥–∞–µ—Ç –¥–∞–º–ø –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–º–æ—â—å—é mysqldump."""
        logger.info("–°–æ–∑–¥–∞–Ω–∏–µ –¥–∞–º–ø–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
        dump_file = temp_dir / f"{self.DB_NAME}.sql"
        command = [str(self.MYSQLDUMP_PATH), f"-u{self.DB_USER}", f"-p{self.DB_PASS}", "--routines", "--triggers", self.DB_NAME]
        
        try:
            with open(dump_file, "w", encoding='utf-8') as f:
                process = await self.run_subprocess(command, stdout=f)
                if process.returncode != 0:
                    raise Exception(f"mysqldump –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –∫–æ–¥–æ–º {process.returncode}")
            logger.info("–î–∞–º–ø –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω.")
            return True
        except FileNotFoundError:
            logger.error(f"–û–®–ò–ë–ö–ê: mysqldump.exe –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ –ø—É—Ç–∏ '{self.MYSQLDUMP_PATH}'")
            return False
        except Exception as e:
            logger.error(f"–û–®–ò–ë–ö–ê –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –¥–∞–º–ø–∞ –ë–î: {e}")
            return False

    async def create_archive(self, archive_path, source_dir):
        """–°–æ–∑–¥–∞–µ—Ç zip-–∞—Ä—Ö–∏–≤ –∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –ø–∞–ø–∫–∏."""
        logger.info(f"–°–æ–∑–¥–∞–Ω–∏–µ –∞—Ä—Ö–∏–≤–∞ '{archive_path.name}'...")
        try:
            await self.bot.loop.run_in_executor(None, lambda:
                shutil.make_archive(str(archive_path.with_suffix('')), 'zip', str(source_dir))
            )
            logger.info("–ê—Ä—Ö–∏–≤ —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω.")
            return True
        except Exception as e:
            logger.error(f"–û–®–ò–ë–ö–ê –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∞—Ä—Ö–∏–≤–∞: {e}")
            return False

    async def backup_code(self, final_archive_path):
        """–ê—Ä—Ö–∏–≤–∏—Ä—É–µ—Ç –∫–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞, –∏—Å–∫–ª—é—á–∞—è –Ω–µ–Ω—É–∂–Ω—ã–µ –ø–∞–ø–∫–∏."""
        logger.info(f"–°–æ–∑–¥–∞–Ω–∏–µ –∞—Ä—Ö–∏–≤–∞ –∫–æ–¥–∞ '{final_archive_path.name}'...")
        exclude_dirs = {'.git', '__pycache__', 'backups_system', 'backups', '.venv', 'logs'}
        try:
            def zip_code():
                with zipfile.ZipFile(final_archive_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                    for file_path in self.BOT_PATH.rglob('*'):
                        if not any(excluded in file_path.parts for excluded in exclude_dirs):
                            zipf.write(file_path, file_path.relative_to(self.BOT_PATH))
            
            await self.bot.loop.run_in_executor(None, zip_code)
            logger.info("–ê—Ä—Ö–∏–≤ –∫–æ–¥–∞ —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω.")
            return True
        except Exception as e:
            logger.error(f"–û–®–ò–ë–ö–ê –ø—Ä–∏ –∞—Ä—Ö–∏–≤–∞—Ü–∏–∏ –∫–æ–¥–∞: {e}")
            return False

    # --- –û–°–ù–û–í–ù–û–ô –ú–ï–¢–û–î, –í–´–ù–ï–°–ï–ù–ù–´–ô –í –û–¢–î–ï–õ–¨–ù–£–Æ –§–£–ù–ö–¶–ò–Æ ---
    async def _run_backup_process(self, manual_run: bool = False) -> Tuple[dict, Optional[str]]:
        if self._is_task_running:
            logger.warning("–ü–æ–ø—ã—Ç–∫–∞ –∑–∞–ø—É—Å—Ç–∏—Ç—å –±—ç–∫–∞–ø, –∫–æ–≥–¥–∞ –æ–Ω —É–∂–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è.")
            return None, None
        
        self._is_task_running = True
        report = {"data_archive": {"status": "–Ω–µ –≤—ã–ø–æ–ª–Ω—è–ª—Å—è", "name": "N/A"},"code_archive": {"status": "–Ω–µ –≤—ã–ø–æ–ª–Ω—è–ª—Å—è", "name": "N/A"}}
        
        logger.info("=== –ù–ê–ß–ê–õ–û –ó–ê–î–ê–ß–ò –†–ï–ó–ï–†–í–ù–û–ì–û –ö–û–ü–ò–†–û–í–ê–ù–ò–Ø ===")
        
        if not self.MYSQLDUMP_PATH.exists():
            logger.critical("–ë—ç–∫–∞–ø –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω: mysqldump.exe –Ω–µ –Ω–∞–π–¥–µ–Ω.")
            self._is_task_running = False
            report["data_archive"]["status"] = "–æ—à–∏–±–∫–∞"
            error_text = f"mysqldump.exe –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ –ø—É—Ç–∏: {self.MYSQLDUMP_PATH}"
            return report, error_text

        now = datetime.datetime.now()
        datestamp = now.strftime("%Y-%m-%d_%H-%M")
        temp_dir = self.LOCAL_BACKUP_PATH / f"temp_{now.timestamp()}"
        temp_dir.mkdir(parents=True, exist_ok=True)
        bot_folder_name = self.BOT_PATH.name
        error_details = None

        try:
            gdrive_service = await self.get_gdrive_service()
            if not gdrive_service:
                raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–µ—Ä–≤–∏—Å Google Drive. –í–æ–∑–º–æ–∂–Ω–æ, —Ç—Ä–µ–±—É–µ—Ç—Å—è —Ä—É—á–Ω–∞—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è.")
            
            main_folder_id = await self.find_or_create_folder(gdrive_service, self.GDRIVE_FOLDER_NAME)
            month_year_str = now.strftime("%m-%Y")
            month_folder_id = await self.find_or_create_folder(gdrive_service, month_year_str, parent_id=main_folder_id)
            
            manual_folder_id = None
            weekly_folder_id = None
            
            # --- –ë—ç–∫–∞–ø –¥–∞–Ω–Ω—ã—Ö ---
            data_prefix = "MANUAL_DATA" if manual_run else "DAILY_DATA"
            logger.info(f"--- –ù–∞—á–∏–Ω–∞—é –±—ç–∫–∞–ø –¥–∞–Ω–Ω—ã—Ö ({data_prefix}) ---")
            data_archive_name = f"{data_prefix}_{bot_folder_name}_{datestamp}.zip"
            
            report["data_archive"]["name"] = data_archive_name
            if await self.backup_database(temp_dir):
                server_backups_path = self.BOT_PATH / "backups"
                if server_backups_path.exists():
                    await self.bot.loop.run_in_executor(None, lambda: shutil.copytree(server_backups_path, temp_dir / "backups"))

                local_data_save_path = self.LOCAL_BACKUP_PATH / month_year_str
                if manual_run:
                    local_data_save_path /= "Manual"
                local_data_save_path.mkdir(parents=True, exist_ok=True)
                data_archive_path = local_data_save_path / data_archive_name

                if await self.create_archive(data_archive_path, temp_dir):
                    data_upload_folder_id = month_folder_id
                    if manual_run:
                        manual_folder_id = await self.find_or_create_folder(gdrive_service, "Manual", parent_id=month_folder_id)
                        data_upload_folder_id = manual_folder_id
                    
                    if await self.upload_file(gdrive_service, data_archive_path, data_upload_folder_id):
                        report["data_archive"]["status"] = "—É—Å–ø–µ—à–Ω–æ"
                        await self.cleanup_old_files(gdrive_service, data_upload_folder_id, self.DATA_RETENTION_DAYS)
                    else:
                        report["data_archive"]["status"] = "–æ—à–∏–±–∫–∞"
                else:
                    report["data_archive"]["status"] = "–æ—à–∏–±–∫–∞"
            else:
                report["data_archive"]["status"] = "–æ—à–∏–±–∫–∞"

            # --- –ë—ç–∫–∞–ø –∫–æ–¥–∞ ---
            if manual_run or now.weekday() == self.CODE_BACKUP_DAY:
                code_prefix = "MANUAL_CODE" if manual_run else "WEEKLY_CODE"
                logger.info(f"--- –ù–∞—á–∏–Ω–∞—é –±—ç–∫–∞–ø –∫–æ–¥–∞ ({code_prefix}) ---")
                code_archive_name = f"{code_prefix}_{bot_folder_name}_{datestamp}.zip"
                
                report["code_archive"]["name"] = code_archive_name
                
                local_code_save_path = self.LOCAL_BACKUP_PATH / month_year_str
                if manual_run:
                    local_code_save_path /= "Manual"
                else:
                    local_code_save_path /= "Weekly"
                local_code_save_path.mkdir(parents=True, exist_ok=True)
                code_archive_path = local_code_save_path / code_archive_name
                
                if await self.backup_code(code_archive_path):
                    code_upload_folder_id = None
                    if manual_run:
                        if not manual_folder_id:
                            manual_folder_id = await self.find_or_create_folder(gdrive_service, "Manual", parent_id=month_folder_id)
                        code_upload_folder_id = manual_folder_id
                    else:
                        weekly_folder_id = await self.find_or_create_folder(gdrive_service, "Weekly", parent_id=month_folder_id)
                        code_upload_folder_id = weekly_folder_id

                    if await self.upload_file(gdrive_service, code_archive_path, code_upload_folder_id):
                        report["code_archive"]["status"] = "—É—Å–ø–µ—à–Ω–æ"
                        await self.cleanup_old_files(gdrive_service, code_upload_folder_id, self.CODE_RETENTION_DAYS)
                    else:
                        report["code_archive"]["status"] = "–æ—à–∏–±–∫–∞"
                else:
                    report["code_archive"]["status"] = "–æ—à–∏–±–∫–∞"
            else:
                report["code_archive"]["status"] = "–ø—Ä–æ–ø—É—â–µ–Ω–æ"
        
        except Exception as e:
            error_details = traceback.format_exc()
            logger.critical(f"–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –≤ –∑–∞–¥–∞—á–µ –±—ç–∫–∞–ø–∞: {e}", exc_info=True)
            report["data_archive"]["status"] = "–æ—à–∏–±–∫–∞"
            report["code_archive"]["status"] = "–æ—à–∏–±–∫–∞"
        finally:
            if temp_dir.exists():
                await self.bot.loop.run_in_executor(None, lambda: shutil.rmtree(temp_dir))
            
            for f in self.LOCAL_BACKUP_PATH.rglob('*.zip'):
                if (now - datetime.datetime.fromtimestamp(f.stat().st_ctime)).days > 2:
                    logger.info(f"–£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä–æ–≥–æ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –±—ç–∫–∞–ø–∞: {f.name}")
                    f.unlink()
            logger.info("=== –ó–ê–î–ê–ß–ê –†–ï–ó–ï–†–í–ù–û–ì–û –ö–û–ü–ò–†–û–í–ê–ù–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê ===")
            self._is_task_running = False
            return report, error_details

    async def _send_backup_report(self, report: dict, recipient: discord.User, error_details: Optional[str] = None):
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –æ—Ç—á–µ—Ç –æ –±—ç–∫–∞–ø–µ –≤ –õ–°."""
        if not report: return
        try:
            lang = self.bot.default_language
            status_map = {
                "—É—Å–ø–µ—à–Ω–æ": self.t("backup.system.report.status_success", lang=lang),
                "–æ—à–∏–±–∫–∞": self.t("backup.system.report.status_failed", lang=lang),
                "–ø—Ä–æ–ø—É—â–µ–Ω–æ": self.t("backup.system.report.status_skipped", lang=lang),
                "–Ω–µ –≤—ã–ø–æ–ª–Ω—è–ª—Å—è": "N/A"
            }
            embed = discord.Embed(title=self.t("backup.system.report.title", lang=lang), color=discord.Color.blue(), timestamp=discord.utils.utcnow())
            embed.add_field(name=self.t("backup.system.report.data_archive_field", lang=lang), value=f"`{report['data_archive']['name']}`\n–°—Ç–∞—Ç—É—Å: {status_map.get(report['data_archive']['status'])}", inline=False)
            embed.add_field(name=self.t("backup.system.report.code_archive_field", lang=lang), value=f"`{report['code_archive']['name']}`\n–°—Ç–∞—Ç—É—Å: {status_map.get(report['code_archive']['status'])}", inline=False)
            if self.bot.guilds:
                embed.set_footer(text=self.t("backup.system.report.footer", lang=lang, guild_name=self.bot.guilds[0].name))
            
            error_file = None
            if error_details:
                buffer = io.StringIO(error_details)
                error_file = discord.File(buffer, filename="backup_error_log.txt")
                embed.color = discord.Color.red()
                embed.add_field(name="üö® –î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏", value="–ü–æ–ª–Ω—ã–π –ª–æ–≥ –æ—à–∏–±–∫–∏ –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω –∫ —ç—Ç–æ–º—É —Å–æ–æ–±—â–µ–Ω–∏—é.", inline=False)

            await recipient.send(embed=embed, file=error_file)
        except Exception as e:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –æ—Ç—á–µ—Ç –æ –±—ç–∫–∞–ø–µ –≤–ª–∞–¥–µ–ª—å—Ü—É: {e}")

    # --- –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ê–Ø –ó–ê–î–ê–ß–ê ---
    @tasks.loop(hours=24)
    async def backup_task(self):
        report, error_details = await self._run_backup_process(manual_run=False)
        owner_id_str = os.getenv("OWNER_DISCORD_ID")
        if owner_id_str and report:
            try:
                owner = await self.bot.fetch_user(int(owner_id_str))
                await self._send_backup_report(report, owner, error_details)
            except Exception as e:
                logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –≤–ª–∞–¥–µ–ª—å—Ü–∞ ({owner_id_str}) –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –æ—Ç—á–µ—Ç–∞: {e}")

    @backup_task.before_loop
    async def before_backup_task(self):
        await self.bot.wait_until_ready()
        now = datetime.datetime.now().astimezone()
        target_time = now.replace(hour=3, minute=0, second=0, microsecond=0)
        if now > target_time:
            target_time += datetime.timedelta(days=1)
        seconds_until_target = (target_time - now).total_seconds()
        logger.info(f"–°–ª–µ–¥—É—é—â–∏–π –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –±—ç–∫–∞–ø —á–µ—Ä–µ–∑ {seconds_until_target / 3600:.2f} —á–∞—Å–æ–≤.")
        await asyncio.sleep(seconds_until_target)

    # --- –ü—Ä–µ—Ñ–∏–∫—Å–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è ---
    @commands.command(name="backup-now", help="[–í–ª–∞–¥–µ–ª–µ—Ü] –ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å –ø–æ–ª–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å –±—ç–∫–∞–ø–∞")
    @is_bot_owner_classic()
    async def backup_now_classic(self, ctx: commands.Context):
        lang = self.bot.default_language
        
        if self._is_task_running:
            await ctx.author.send(self.t("backup.system.task_already_running", lang=lang))
            return
            
        await ctx.author.send(self.t("backup.system.now_started", lang=lang))
        
        if ctx.guild:
            try: await ctx.message.delete()
            except discord.Forbidden: pass

        async def run_and_report():
            report, error_details = await self._run_backup_process(manual_run=True)
            await self._send_backup_report(report, ctx.author, error_details)
        self.bot.loop.create_task(run_and_report())

    @commands.command(name="backup-status", help="[–í–ª–∞–¥–µ–ª–µ—Ü] –ü–æ–∫–∞–∑–∞—Ç—å –≤—Ä–µ–º—è –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –±—ç–∫–∞–ø–∞")
    @is_bot_owner_classic()
    async def backup_status_classic(self, ctx: commands.Context):
        lang = self.bot.default_language
        next_run = self.backup_task.next_iteration
        
        if not next_run:
            await ctx.author.send("–ó–∞–¥–∞—á–∞ –±—ç–∫–∞–ø–∞ –Ω–µ –∑–∞–ø—É—â–µ–Ω–∞.")
            return
            
        delta = next_run - discord.utils.utcnow()
        hours, remainder = divmod(int(delta.total_seconds()), 3600)
        minutes, _ = divmod(remainder, 60)
        
        await ctx.author.send(self.t("backup.system.status_message", lang=lang, hours=hours, minutes=minutes))
        
        if ctx.guild:
            try: await ctx.message.delete()
            except discord.Forbidden: pass

async def setup(bot: "SecurityBot"):
    await bot.add_cog(BackupManagerCog(bot))